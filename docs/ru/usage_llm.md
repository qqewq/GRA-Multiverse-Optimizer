# Использование GRA-Multiverse-Optimizer для Anti‑Hallucination в LLM

Этот документ описывает, как использовать **GRA-Multiverse-Optimizer** как **Anti‑Hallucination‑ядро** поверх больших языковых моделей (LLM).

Фокус — на практике: как подать несколько ответов в мультиверс, как используются функционалы «пены» \(\Phi^{(l)}\) и как встроить это в реальный LLM‑пайплайн.

---

## 1. Концепция

Мы интерпретируем несколько ответов LLM (или несколько сэмплов одной LLM) как **мультиверс гипотез**:

- **Уровень 0**: отдельные ответы \(\Psi^{(0,a)}\) от одной или нескольких LLM.  
- **Уровень 1**: согласованность между ответами (парная консистентность).  
- **Уровень 2**: согласованность с внешним контекстом (RAG‑документы, база знаний, инструменты).

На каждом уровне \(l\) вводится функционал «пены» \(\Phi^{(l)}\), измеряющий несогласованность:

- \(\Phi^{(0)}\): внутренние противоречия в одном ответе (например, конфликтующие числа, сущности).  
- \(\Phi^{(1)}\): расхождения между разными ответами (семантическая дистанция, несовпадение сущностей).  
- \(\Phi^{(2)}\): расхождение с внешним контекстом (документы, проверенные факты).

Мультиверсный функционал

\[
J_{\text{multiverse}}(\mathbf{\Psi}) =
\sum_{l=0}^K \Lambda_l \sum_{\dim(\mathbf{a})=l} J^{(l)}(\Psi^{(\mathbf{a})})
\]

минимизируется в состоянии **когнитивного вакуума** — ответе (или ансамбле ответов) с минимальной пеной и максимальной межуровневой согласованностью.

---

## 2. Базовый API: `optimize_answers`

Главная высокоуровневая точка входа для LLM‑сценариев:

```python
from gra_multiverse.llm_module import optimize_answers
