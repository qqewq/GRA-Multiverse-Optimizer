# GRA Multiverse LLM Anti‑Hallucination Demo

This notebook demonstrates how to use **GRA-Multiverse-Optimizer** as an **Anti‑Hallucination Core** on top of multiple LLM answers.

We will:
- create a small multiverse of candidate answers,
- use `optimize_answers` to select a GRA-consistent answer,
- inspect per-level foam / risk scores.
# 1. Setup: imports and simple helpers

from gra_multiverse.llm_module import optimize_answers

def show_results(title, result, answers):
    print("=" * 80)
    print(title)
    print("=" * 80)
    print("Candidate answers:\n")
    for i, a in enumerate(answers):
        print(f"[{i}] {a}")
    print("\n---")
    print("Final answer:\n")
    print(result["answer"])
    print("\nChosen index:", result.get("chosen_index"))
    print("Scores:", result.get("scores"))
## 2. Toy fact example

We construct three answers to a simple factual question. One of them is wrong.
The Anti‑Hallucination Core should prefer the consistent answers about Paris being the capital of France.
question = "What is the capital of France?"

answers = [
    "Paris is the capital of France.",
    "Paris is a large city in Germany.",
    "The capital of France is Paris.",
]

context_documents = [
    "France is a country in Europe. Its capital is Paris."
]

result_toy = optimize_answers(
    answers=answers,
    context_documents=context_documents,
    lambda_levels={0: 0.5, 1: 1.0, 2: 2.0},
)

show_results("Toy fact example", result_toy, answers)
## 3. RAG-style example

In a more realistic setting, answers are generated from an LLM given a prompt and a set of documents (RAG).
Here we emulate this by hard-coding short documents and candidate answers.

The goal is for the optimizer to select an answer that both:
- agrees with other candidates,
- and is consistent with the documents.
question = "What is GRA-Multiverse-Optimizer?"

docs = [
    "GRA-Multiverse-Optimizer is a prototype backend for multilevel GRA Meta-Obnulyonka.",
    "It treats many interacting models or configurations as a multiverse state.",
]

answers = [
    "GRA-Multiverse-Optimizer is a video game engine.",
    "GRA-Multiverse-Optimizer is a prototype backend for multilevel GRA Meta-Obnulyonka.",
    "It is a library that treats many interacting models or configs as a multiverse and optimizes their consistency.",
]

result_rag = optimize_answers(
    answers=answers,
    context_documents=docs,
    lambda_levels={0: 0.3, 1: 0.7, 2: 1.5},
)

show_results("RAG-style example", result_rag, answers)
## 4. Summary

In this demo we used **GRA-Multiverse-Optimizer** as an Anti‑Hallucination Core:

- multiple candidate answers were treated as a multiverse of hypotheses,
- the `optimize_answers` function selected answers with lower multilevel foam,
- per-level scores (`scores`) can be used as a “hallucination risk” signal.

This pattern can be plugged into real LLM pipelines (RAG, multi-model ensembles, chatbots)
without retraining the underlying models.
